---
title: "Circular Dataset Structures"
date: "`r Sys.Date()`"
author: "James Foster"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Details

> **AUTHOR**
>
> James Foster

> **DESCRIPTION**
>
> Examination of different dataset structures that may arise in the study of animal navigation.

> **INPUTS**
>
> `unwrap_functions.R`

> **OUTPUTS**
>
> Plotted results.

> **REFERENCES**
>
> **data types**
>
> Duelli P. & Wehner R.
> (1973) The Spectral Sensitivity of Polarized Light Orientation in Cataglyphis bicolor ( Formicidae , Hymenoptera ) *Journal of Comparative Physiology* 53(3) 37-53
>
> Edrich, W., Neumeyer, C.
> and von Helversen, O.
> (1979).
> ‚ÄúAnti-sun orientation‚Äù of bees with regard to a field of ultraviolet light.
> *J. Comp. Physiol.* 134, 151‚Äì157.
>
> **modelling methods**
>
> Sayin S, Couzin-Fuchs E, Petelski I, G√ºnzel Y, Salahshour M, Lee CY, Graving JM, Li L, Deussen O, Sword GA, et al. (2025) The behavioral mechanisms governing collective motion in swarming locusts.
> Science.
> 387(6737):995‚Äì791
>
> Gabry J, ƒåe≈°novar R, Johnson A (2022).
> cmdstanr: R Interface to 'CmdStan'.
> <https://mc-stan.org/cmdstanr/>
>
> B√ºrkner, P.-C.
> (2018).
> Advanced Bayesian Multilevel Modeling with the R Package brms.
> The R Journal 10, 395‚Äì411.
>
> Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P. and Riddell, A.
> (2017).
> Stan: A Probabilistic Programming Language.
> Journal of Statistical Software 76 doi: 10.18637/jss.v076.i01

> **TODO**
>
> -   move necessary functions to unwrap_functions.R
> -   make functions for result extraction from BRMS

## Set up workspace

```{r Load functions and packages}
source('unwrap_functions.R')
```

Set up some colours for plotting.

```{r Set up plot colours}
col_kappa = '#1E78B5'#colour for kappa parameter
col_rho = '#F08024' #colour for mean vector length
col_sd = '#E74A29' #colour for SD and mean angle
col_sd2 = '#E57461' #colour for other SD heuristics
col_pdf = adjustcolor(col = '#21A885', # colour for probability density
                      alpha.f = 0.7)
col_obs = '#3E1F51' #colour for control observations
col_treat = '#006400' # colour for treatment observations
```

# Divergence from home direction

In navigation experiments return directions are often compared with the expected home direction to determine if homeward navigation is perturbed.
Here, we simulate example data (ùëõ = 20) generated from a distribution with a mean differs that from the expected direction (0¬∞) by only 15¬∞.

```{r Generate diverging data, echo  = FALSE}
ndata = 20 #sample size

# circular zero expected angle
c0 = circular(x = 0,
              units = 'degrees',
              rotation = 'clock',
              zero = pi/2)
#true mean angle
c15 = circular(x = -15,
              units = 'degrees',
              rotation = 'clock',
              zero = pi/2)

par(pty = 's') # square axes
par(mar = c(0,0,0,0)) # no margins

cd_divergence = DescriptCplot(m = -15, # population mean
                              k = 10, # high concentration
                              refline = 0, # expected direction
                              ndata = ndata,
                              mvcol = col_obs, #distr. mean same colour as observations
                              sdcol = NA, # don't plot SD
                              denscol = NA, # don't plot prob. density
                              save_sample = TRUE)
```

A common shortcut to assess orientation in an expected direction is to use the v-test modification of the Rayleigh test for uniformity.
This tests the hypothesis of uniformity against the alternative of clustering in some direction near the expected direction.
The data are very far from uniform ($\kappa = 10$), and the mean angle is very close to the expected angle (cosine similarity of `cos(rad(-15)) = 97%`), so the test is significant.
Even so, the data show a trend away from the expected angle, 75% of points falling to the left of 0¬∞.

```{r v-test for uniformity}
mean(cd_divergence < 0)
rayleigh.test(cd_divergence, mu = c0)

```

## Fit the model

In order to fit a circular model using the shifted modulo and softplus links, we need to define a custom family.
This family

```{r Set up the circular model custom family}
#set up required Stan functions
#shifted modulo in Stan code
model_circular_fun = stanvar(scode = "
  real model_circular(real y) {
    return fmod(y + pi(), 2*pi()) - pi();
  }
",
                           block = 'functions')

#custom likelihood function using the shifted modulo link
stan_unwrap_fun = stanvar(scode = "
  real unwrap_von_mises_lpdf(real y, real mu, real kappa) {
    return von_mises_lpdf(y | model_circular(mu), kappa);
  }
  real unwrap_von_mises_rng(real mu, real kappa) {
    return von_mises_rng( model_circular(mu) , kappa);
  }
",
                          block = 'functions') 
#define the custom family
unwrap_von_mises = custom_family(
  name = "unwrap_von_mises",
  dpars = c("mu",
            "kappa"),
  links = c('identity',#N.B. the link function is defined via the LPD function
            "softplus"), 
  lb = c(-pi,#lower bound of mu should be -pi
         0),
  ub = c(pi,#upper bound of mu should be pi
         NA),
  type = "real",#takes continuous response data
  # vars = stan_unwrap_fun + model_circular_fun
)

```

To fit out model, we need to convert our data from degrees to radians.
It is also recommended to remove additional formatting by converting from class "circular" to class "numeric".
Our formula indicates that each of mu and kappa require a single parameter estimate (`~1`).
In this data, we expect a mean direction anywhere on the circle (within $\pi$ of the mean) and high concentration ($\kappa>1$), so highest prior density is set in that range.

```{r Fit a model to the divergence data}
#reformat data for BRMS
dt_divergence = data.frame(y = as.numeric(#remove circular formatting
                                rad(cd_divergence)#convert to radians
                                )
                           )#make a data frame

#formula for a circular model with no predictors
form_divergence = bf(y~1,
                     kappa~1,
                     family = unwrap_von_mises)
#unbiased priors
prior_divergence =  prior('normal(0,2*pi())', class = 'Intercept', dpar = 'mu') +
                     prior('normal(3,3)', class = 'Intercept', dpar = 'kappa')

#fit a generic unwrap model
model_divergence = brm(formula = form_divergence,
             data = dt_divergence,
             family = unwrap_von_mises,
             stanvars = stan_unwrap_fun + model_circular_fun,
             prior = prior_divergence,
             silent = 2,
             backend = 'cmdstan'#faster and more reliable
  )

summary(model_divergence)
```

Since the mean direction is far from the wrap-point ($-\pi$ or $\pi$), the `Rhat` convergence heuristic for the mu `Intercept` can be interpreted on the linear scale.
`Rhat` values for both parameters are $<1.01$ and effective sample size (ESS) indicates most of the 4000 draws explored the posterior distribution efficiently, so we can assume that this model has converged.

To inspect the model's predictions, we can extract the post-warmup draws from the model and plot the posterior distribution of estimates alongside the original data.
$\mu$ `Intercept` can be plotted as an angle in radians on its original scale.
For $\kappa$, we need to convert estimates to the correct scale using the `softplus` transform ($\log( \exp(x) + 1)$) and then convert it to mean-vector-length scale using the `A1` function. There are `4000` posterior estimates, so rather than plotting all of them we'll summarise them as the medians of $\mu$ and $\kappa$ estimates and the normalised 2D kernel density of their mean-vector equivalent.

```{r Plot the model fitted for divergence data}
draws_divergence = as_draws_df(model_divergence)


par(pty = 's')
par(mar = c(0,0,0,0),
    mfrow = c(1,2))
PCfun(cd_divergence,
      col = col_obs,
      sep = 0.05,
      shrink = 1.25,
      plot_rho = FALSE)
Draws2Cont(draws_divergence,
           x_string = )
arrows.circular(x = circular(-15,
                             units = 'degrees',
                             rotation = 'clock',
                             zero = pi/2),
                y = A1(10),
                col = col_obs,
                lwd = 5,
                length = 0.1/1.25
)


with(draws_divergence,
     arrows.circular(x = median.circular(x =
                                           circular(Intercept,
                                  rotation = 'clock',
                                  zero = pi/2)
                                  ),
                     y = A1(softplus(x = median(x = Intercept_kappa))),
                     lwd = 2,
                     length = 0.1/1.25,
                     col = adjustcolor(col_sd, alpha.f = 200/255))
)
with(draws_divergence,
     {
      VertHist(data = deg(Intercept), 
               main = '\nmean angle',
               ylim = c(-30, 15),
               col = adjustcolor(col_sd, alpha.f = 100/255),
               cex.axis = 0.7)
     }
)
abline(h = 0,
       col = 'gray',
       lwd = 7)

with(draws_divergence,
     {
       paste0('mu left of expected angle: ',
              mean(Intercept < 0)*100, '%')
      }
     ) #nearly all estimates suggest a rightwards turn
```

The fitted model indicates that the mean direction is to the left of the expected direction in $>99\%$ of ùúá estimates.

## Test the expected angle hypothesis

To test the hypothesis that the true mean direction falls in the expected direction, we can fit another model where this is explicitly stated.
To inform BRMS that we do not want to estimate the mean direction, we use the notation `y~0`, which removes the intercept parameter.
We can now estimate $\kappa$, *assuming* that the mean direction is 0¬∞, using the same prior for kappa as before.

```{r Model comparison observed vs expected mean direction}


#fit a model with mean at 0
model_expect = brm(formula = bf(y~0,
                              kappa~1),
                data = dt_divergence,
                family = unwrap_von_mises,
                prior = prior_divergence[2,], # just the kappa prior,
                stanvars = stan_unwrap_fun + model_circular_fun,
                silent = 2,
                backend = 'cmdstan'
                )
#add Leave-One-Out Cross-Validation

loo_divergence = loo(model_divergence)
loo_expected = loo(model_expect)
loo_compare(loo_divergence, loo_expected)
```
The model for a divergent mean direction has higher expected log predictive density (ELPD) than the model for the expected direction.
This ELPD difference is $>2\times$ larger than its standard error, so we can state with some confidence that the hypothesis of a divergence from the expected direction is more likely than the hypothesis of alignment with the expected direction.

In this case, the expected angle model is straightforward to fit because the expected angle is 0¬∞, which is also the default intercept for a `y~0` (no-intercept) model.
If the expected direction were not 0¬∞, we would need to adjust the data to align the expected angle with the `0` intercept, then fit both models (expected direction and divergent direction) to the adjusted data.
Here is an example with the expected angle at -15¬∞.

```{r Model comparison for expected angle not at 0}
#align the data relative to the expected angle
dt_aligned = within(dt_divergence,
                    {
                    y = y - rad(-15)  #subtract the expected angle
                    }
                    )


#we now place our expected angle at -15¬∞, the true mean
model_true = brm(formula = bf(y ~ 0,
                            kappa~1),
               data = dt_aligned, 
               family = unwrap_von_mises,
               prior = prior_divergence[2,], # just the kappa prior
               stanvars = stan_unwrap_fun + model_circular_fun,
               silent = 2,
               backend = 'cmdstan'
)

#this model should be compared with another fitted to the
#_same data_
model_false =  brm(formula = bf(y ~ 1,
                            kappa~1),
               data = dt_aligned, 
               family = unwrap_von_mises,
               prior = prior_divergence, # the kappa and mu priors
               stanvars = stan_unwrap_fun + model_circular_fun,
               silent = 2,
               backend = 'cmdstan'
)

#both models converge well with rhats [1.000, 1.002]
sm_truefalse = lapply(list(true = model_true, false = model_false), summary)
#their mu estimates are very close, differing by only 2¬∞, with overlapping CI.
round( deg(
  sm_truefalse$false$fixed['Intercept',
                                    1:4]
  ) )

#add Leave-One-Out Cross-Validation
loo_true = loo(model_true)
loo_false = loo(model_false)
loo_compare(loo_true, loo_false)
```

Now the expected direction model has higher predictive power, even though both find a similar mean direction. If the divergence model had higher predictive power, but within one standard error of the expected direction model, we could not rule out that the expected direction is the true direction, though evidence would be weaker.

#Change in direction
If the expected direction is not known, it can be estimated from control data and compared with treatment data. In this example, the two distributions have different random number seeds, to avoid producing two identical distributions of angles with a fixed shift.
```{r Simulate a change in direction}
par(pty = 's')
par(mar = c(0,0,0,0))
par(mfrow = c(1,2))

cd_control = DescriptCplot(m = 180,
                     k = 3,
                     ndata = ndata,
                     mvcol = col_obs,
                     sdcol = NA,
                     denscol = NA,
                     refline = c0,
                     save_sample = TRUE,
                     titleline = -1,#needs to be lower when data are South
                     seed = 1539571)#DOI Papi & Pardi

cd_treatment = DescriptCplot(m = 210,
                       k = 3,
                       ndata = ndata,
                       pcol = col_treat,
                       mvcol = col_treat,
                       sdcol = NA,
                       denscol = NA,
                       refline = c0,
                       save_sample = TRUE,
                       titleline = -1,#needs to be lower when data are South
                     seed = 0120810506) #ISBN Batschelet 1981


```

To model the change in direction, we need to account for potential differences in both direction and concentration between the control and treatment. We can combine our two sets of angles together into one vector $y$, that is aligned with the vector $x$, which specifies whether the treatment was applied in Boolean logic (yes: $1$, no: $0$).
N.B. For stability, a slightly narrower prior on `Intercept`, $N(0,3\pi/2)$, is used. This reduces the region of $50\%$ prior density from [-240¬∞, 240¬∞] to [-180¬∞, 180¬∞]. 

```{r Fit treatment direction model}
dt_delta = data.frame(y = rad(
                            as.numeric(
                            c(cd_control,
                              cd_treatment)
                            ) ),
                      x = c(rep(0, length(cd_control)),
                            rep(1, length(cd_treatment)))
                      )

#formula for a circular model with no predictors
form_delta = bf(y~x,
                kappa~x,
                family = unwrap_von_mises)

prior_delta = prior('normal(0,3*pi()/2)', class = 'Intercept', dpar = 'mu') +
        prior('normal(0,pi()/2)', class = 'b', dpar = 'mu') +
        prior('normal(3,3)', class = 'Intercept', dpar = 'kappa') +
        prior('normal(0,3)', class = 'b', dpar = 'kappa')


model_delta =  brm(formula = form_delta,
               data = dt_delta, 
               family = unwrap_von_mises,
               prior = prior_delta, # the kappa and mu priors
               stanvars = stan_unwrap_fun + model_circular_fun,
               silent = 2,
               backend = 'cmdstan'
)
summary(model_delta)
```
Because the mean direction for the control now falls precisely at the boundary of $(-\pi, \pi)$, estimates for the `Intercept` parameter with equal likelihood appear in both positive and negative directions. The same is also possible for the coefficient `b_x` (treatment change in angle). If we unwrap these estimates, we can see that they actually converged towards the same angle, but in different directions.
```{r Unwrap the intercept estimates}
plot(model_delta)
#unwrap estimates and convert to degrees
plot(x = model_delta,
     variable = c('Intercept','b_x'),
     transform = unwrap_circular_deg)
#print the rhat for unwrapped estimates
UnwrapRhats(model_delta,
            variable = c('Intercept','b_x'),
            regex = FALSE
            )
```
Now that we have established that the model has converged, we can inspect the model predictions
```{r Inspect predictions for change in direction}
draws_delta = as_draws_df(model_delta)

par(pty = 's')
par(mar = c(0,0,0,0),
    mfrow = c(1,3))
PCfun(cd_control,
      col = col_obs,
      sep = 0.05,
      shrink = 1.25,
      plot_rho = FALSE)
Draws2Cont(draws_delta,
           x_string = 'sin(Intercept)*A1(softplus(Intercept_kappa))',
           y_string = 'cos(Intercept)*A1(softplus(Intercept_kappa))',
)
arrows.circular(x = circular(180,
                             units = 'degrees',
                             rotation = 'clock',
                             zero = pi/2),
                y = A1(3),
                col = col_obs,
                lwd = 5,
                length = 0.1/1.25
)
with(draws_delta,
     arrows.circular(x = median.circular(x =
                             circular(Intercept,
                                  rotation = 'clock',
                                  zero = pi/2)
                                  ),
                     y = A1(softplus(x = median(x = Intercept_kappa))),
                     lwd = 2,
                     length = 0.1/1.25,
                     col = adjustcolor(col_sd, alpha.f = 200/255))
)

PCfun(cd_treatment,
      col = col_treat,
      sep = 0.05,
      shrink = 1.25,
      plot_rho = FALSE)
Draws2Cont(draws_delta,
           x_string = 'sin(Intercept+b_x)*A1(softplus(Intercept_kappa+b_kappa_x))',
           y_string = 'cos(Intercept+b_x)*A1(softplus(Intercept_kappa+b_kappa_x))',
)
arrows.circular(x = circular(205,
                             units = 'degrees',
                             rotation = 'clock',
                             zero = pi/2),
                y = A1(3),
                col = col_treat,
                lwd = 5,
                length = 0.1/1.25
)
with(draws_delta,
     arrows.circular(x = median.circular(x =
                             circular(Intercept + b_x,
                                  rotation = 'clock',
                                  zero = pi/2)
                                  ),
                     y = A1(softplus(x = median(x = Intercept_kappa +
                                                  b_kappa_x))),
                     lwd = 2,
                     length = 0.1/1.25,
                     col = adjustcolor(col_sd, alpha.f = 200/255))
)
with(draws_delta,
     VertHist(data = Mod360.180(deg(b_x)), 
              main = 'change in mean angle',
              ylim = c(-90, 90),
              col = adjustcolor(col_sd, alpha.f = 100/255),
              axes = F,
              cex.axis = 0.7))
abline(h = 0,
       col = 'gray',
       lwd = 7)
axis(1)
axis(2, at = -6:6*15)

with(draws_delta, paste0(mean(b_x > 0)*100, '%') ) #nearly all estimates suggest a rightwards turn

with(draws_delta, paste0( round(
                        deg(median.circular(x =
                             circular(b_x,
                                  template = 'none')
                                  )
                            ) ), 
                            '¬∞')
     ) #the size recovered is similar to the simulated turn of 210-180

watson.two.test(cd_control, cd_treatment)#no difference detected


```
Uncertainty in the example data results in a wide range of posterior estimates for the treatment direction. Nonetheless, $\>95\%$ of estimates for change in ùúá are to the right of 0¬∞, suggesting a change in direction.

## Test the direction change hypothesis
We can investigate this further with model comparison by fitting models with no effects of treatment, and effects on only kappa.

```{r LOO-CV direction change}
#model with effects of treatment on kappa, but not mu
model_kappadelta =  brm(formula = bf(y~1,
                                     kappa~x),
               data = dt_delta, 
               family = unwrap_von_mises,
               prior = prior_delta[c(1,3:4),], # the all kappa & 1st mu prior
               stanvars = stan_unwrap_fun + model_circular_fun,
               silent = 2,
               backend = 'cmdstan'
)
#model with no effects of treatment
model_nodelta =  brm(formula = bf(y~1,
                                  kappa~1),
               data = dt_delta, 
               family = unwrap_von_mises,
               prior = prior_delta[c(1,3),], # intercept kappa & mu priors
               stanvars = stan_unwrap_fun + model_circular_fun,
               silent = 2,
               backend = 'cmdstan'
)
#all models converge well
print(
  list(`treat. kappa` = 
    summary(model_kappadelta),
    `unwrapped rhat` = 
    UnwrapRhats(model_kappadelta,
                variable = c('Intercept'),
                regex = FALSE
                ),
    `no treat.` = 
    summary(model_nodelta),
    `unwrapped rhat no treat.` = 
    UnwrapRhats(model_nodelta,
                variable = c('Intercept'),
                regex = FALSE
                )
    ),
  digits = 3
)

loo_delta = loo(model_delta)
loo_kappadelta = loo(model_kappadelta)
loo_nodelta = loo(model_nodelta)
print(loo_compare(loo_delta, loo_kappadelta, loo_nodelta))
```
In this case there is uncertainty about the effect of treatment on direction. Although the model with a change in direction indicates that change to be very consistent (95% CI do not overlap with 0¬∞), these differences could be explained well by a null model with no change. Since the median estimate is close to the true value of 30¬∞, the model's estimates appear to be robust, if not conclusive. Conversely, we can conclude that there was no effect of treatment on concentration, since `model_kappadelta` is a much worse fin that the null model (`model_nodelta`).

#Change in concentration 
An experimental treatment may also affect concentration independently of mean direction.
```{r Simulate a decrease in concentration}
par(pty = 's')
par(mar = c(0,0,0,0))
par(mfrow = c(1,2))

cd_3 = DescriptCplot(m = 0,
                     k = 3,
                     ndata = ndata,
                     mvcol = col_obs,
                     sdcol = NA,
                     denscol = NA,
                     refline = c0,
                     save_sample = TRUE)
cd_0.5 = DescriptCplot(m = 0,
                       k = 0.5,
                       ndata = 20,
                       pcol = col_treat,
                       mvcol = col_treat,
                       sdcol = NA,
                       denscol = NA,
                       refline = c0,
                       save_sample = TRUE)
```